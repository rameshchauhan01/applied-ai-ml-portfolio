{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Cgc1UInNrVGK"
      },
      "outputs": [],
      "source": [
        "from collections import defaultdict, Counter\n",
        "import numpy as np\n",
        "\n",
        "# Example train and test corpus (list of sentences)\n",
        "train_corpus = [\n",
        "    \"a quick brown fox jumps over the lazy dog\",\n",
        "    \"the fox is quick and brown\",\n",
        "    \"quick brown fox\",\n",
        "]\n",
        "test_corpus = [\n",
        "    \"a quick fox jumps\",\n",
        "    \"the dog is lazy\",\n",
        "]\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_ngrams(sentence, n):\n",
        "    words = ['<s>'] * (n - 1) + sentence.split() + ['</s>']\n",
        "    return [tuple(words[i:i+n]) for i in range(len(words) - n + 1)]\n",
        "\n",
        "def count_ngrams(corpus, n):\n",
        "    ngram_counts = Counter()\n",
        "    for sent in corpus:\n",
        "        ngram_counts.update(get_ngrams(sent, n))\n",
        "    return ngram_counts\n"
      ],
      "metadata": {
        "id": "KacYtHxgrZ0l"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LaplaceNGramLM:\n",
        "    def __init__(self, corpus, n):\n",
        "        self.n = n\n",
        "        self.ngram_counts = count_ngrams(corpus, n)\n",
        "        self.nm1gram_counts = count_ngrams(corpus, n-1) if n > 1 else None\n",
        "        self.vocab = set(word for sent in corpus for word in sent.split())\n",
        "        self.vocab_size = len(self.vocab)\n",
        "    def prob(self, ngram):\n",
        "        if self.n == 1:\n",
        "            c = self.ngram_counts[ngram]\n",
        "            return (c + 1) / (sum(self.ngram_counts.values()) + self.vocab_size)\n",
        "        else:\n",
        "            c = self.ngram_counts[ngram]\n",
        "            d = self.nm1gram_counts[ngram[:-1]]\n",
        "            return (c + 1) / (d + self.vocab_size)\n",
        "    def sent_prob(self, sentence):\n",
        "        ngrams = get_ngrams(sentence, self.n)\n",
        "        return np.product([self.prob(ngram) for ngram in ngrams])\n"
      ],
      "metadata": {
        "id": "fzuDMAj4rdXc"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class InterpolatedNGramLM:\n",
        "    def __init__(self, corpus, n, lambdas=None):\n",
        "        self.n = n\n",
        "        self.ngram_counts = [count_ngrams(corpus, i+1) for i in range(n)]\n",
        "        self.vocab = set(word for sent in corpus for word in sent.split())\n",
        "        self.vocab_size = len(self.vocab)\n",
        "        self.lambdas = lambdas or [1/n] * n\n",
        "    def prob(self, ngram):\n",
        "        probs = []\n",
        "        for i in range(self.n):\n",
        "            gram = ngram[-(i+1):]\n",
        "            if i == 0:\n",
        "                prob = (self.ngram_counts[0][(gram[0],)] + 1) / (sum(self.ngram_counts[0].values()) + self.vocab_size)\n",
        "            else:\n",
        "                d = self.ngram_counts[i-1][gram[:-1]]\n",
        "                prob = (self.ngram_counts[i][gram] + 1) / (d + self.vocab_size)\n",
        "            probs.append(self.lambdas[i] * prob)\n",
        "        return sum(probs)\n",
        "    def sent_prob(self, sentence):\n",
        "        ngrams = get_ngrams(sentence, self.n)\n",
        "        return np.product([self.prob(ngram) for ngram in ngrams])\n"
      ],
      "metadata": {
        "id": "WiVnJ8sKrjQ7"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class InterpolatedNGramLM:\n",
        "    def __init__(self, corpus, n, lambdas=None):\n",
        "        self.n = n\n",
        "        self.ngram_counts = [count_ngrams(corpus, i+1) for i in range(n)]\n",
        "        self.vocab = set(word for sent in corpus for word in sent.split())\n",
        "        self.vocab_size = len(self.vocab)\n",
        "        self.lambdas = lambdas or [1/n] * n\n",
        "    def prob(self, ngram):\n",
        "        probs = []\n",
        "        for i in range(self.n):\n",
        "            gram = ngram[-(i+1):]\n",
        "            if i == 0:\n",
        "                prob = (self.ngram_counts[0][(gram[0],)] + 1) / (sum(self.ngram_counts[0].values()) + self.vocab_size)\n",
        "            else:\n",
        "                d = self.ngram_counts[i-1][gram[:-1]]\n",
        "                prob = (self.ngram_counts[i][gram] + 1) / (d + self.vocab_size)\n",
        "            probs.append(self.lambdas[i] * prob)\n",
        "        return sum(probs)\n",
        "    def sent_prob(self, sentence):\n",
        "        ngrams = get_ngrams(sentence, self.n)\n",
        "        return np.product([self.prob(ngram) for ngram in ngrams])\n"
      ],
      "metadata": {
        "id": "cc_QSNpErnG0"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def perplexity(lm, corpus):\n",
        "    N = 0\n",
        "    log_prob = 0\n",
        "    for sent in corpus:\n",
        "        ngrams = get_ngrams(sent, lm.n)\n",
        "        for ng in ngrams:\n",
        "            prob = lm.prob(ng)\n",
        "            if prob == 0: # Avoid log(0)\n",
        "                prob = 1e-10\n",
        "            log_prob += -np.log(prob)\n",
        "            N += 1\n",
        "    return np.exp(log_prob / N)\n",
        "\n",
        "unigram_laplace = LaplaceNGramLM(train_corpus, 1)\n",
        "bigram_laplace = LaplaceNGramLM(train_corpus, 2)\n",
        "trigram_laplace = LaplaceNGramLM(train_corpus, 3)\n",
        "\n",
        "print(\"Bigram Laplace Perplexity:\", perplexity(bigram_laplace, test_corpus))\n",
        "print(\"Trigram Interpolation Perplexity:\",\n",
        "      perplexity(InterpolatedNGramLM(train_corpus, 3, [0.2, 0.3, 0.5]), test_corpus))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gulaslwvrtSS",
        "outputId": "b39f7221-2126-4373-f640-656d8738c44a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bigram Laplace Perplexity: 9.291313290738232\n",
            "Trigram Interpolation Perplexity: 9.485268178704718\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_next_word(lm, prefix):\n",
        "    prefix = prefix.split()\n",
        "    if len(prefix) < lm.n - 1:\n",
        "        prefix = ['<s>'] * (lm.n - 1 - len(prefix)) + prefix\n",
        "    else:\n",
        "        prefix = prefix[-(lm.n - 1):]\n",
        "    candidates = list(lm.vocab)\n",
        "    scores = []\n",
        "    for cand in candidates:\n",
        "        ngram = tuple(prefix + [cand])\n",
        "        scores.append((cand, lm.prob(ngram)))\n",
        "    scores.sort(key=lambda x: -x[1])\n",
        "    return scores[:3]\n",
        "\n",
        "# Example for 'a quick'\n",
        "print(\"Predictions:\", predict_next_word(bigram_laplace, 'a quick'))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HHOchx3grw-P",
        "outputId": "69596cff-bee8-4a24-b0b0-37cb2dc2028a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions: [('brown', 0.21428571428571427), ('and', 0.14285714285714285), ('quick', 0.07142857142857142)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class StupidBackoffNGramLM:\n",
        "    def __init__(self, corpus, n, alpha=0.4):\n",
        "        self.n = n\n",
        "        self.alpha = alpha\n",
        "        self.counts = [count_ngrams(corpus, i+1) for i in range(n)]\n",
        "        self.vocab = set(word for sent in corpus for word in sent.split())\n",
        "        self.total_unigrams = sum(self.counts[0].values())\n",
        "\n",
        "    def score(self, ngram):\n",
        "        n = len(ngram)\n",
        "        if n == 1:\n",
        "            return self.counts[0][ngram] / self.total_unigrams\n",
        "        elif self.counts[n-1][ngram] > 0:\n",
        "            prefix = ngram[:-1]\n",
        "            return self.counts[n-1][ngram] / self.counts[n-2][prefix]\n",
        "        else:\n",
        "            # Recursively back off to lower order, multiplying by alpha\n",
        "            return self.alpha * self.score(ngram[1:])\n",
        "\n",
        "    def sent_score(self, sentence):\n",
        "        ngrams = get_ngrams(sentence, self.n)\n",
        "        scores = [self.score(ngram) for ngram in ngrams]\n",
        "        # For product of scores; to avoid underflow, work in log space if needed\n",
        "        return np.product(scores)\n"
      ],
      "metadata": {
        "id": "JClnyHW3r0Xq"
      },
      "execution_count": 8,
      "outputs": []
    }
  ]
}
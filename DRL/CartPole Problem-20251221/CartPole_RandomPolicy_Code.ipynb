{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install gymnasium\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I4aKFchyFfLz",
        "outputId": "0caa98e6-bba0-4a4f-8fff-e7100f823c27"
      },
      "id": "I4aKFchyFfLz",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gymnasium in /usr/local/lib/python3.12/dist-packages (1.2.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium) (2.0.2)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium) (3.1.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium) (4.15.0)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.12/dist-packages (from gymnasium) (0.0.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "37837f6c",
      "metadata": {
        "id": "37837f6c"
      },
      "source": [
        "# Exercise 1: Random Policy on CartPole-v1\n",
        "**Course:** Introduction to Reinforcement Learning  \n",
        "**Difficulty:** Easy  \n",
        "**Objective:** Implement and analyze a random policy in CartPole-v1.\n",
        "\n",
        "---\n",
        "### Learning Objectives\n",
        "\n",
        "- Set up and interact with the CartPole environment.\n",
        "- Implement a random policy.\n",
        "- Track cumulative rewards per episode.\n",
        "- Analyze performance of random actions.\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "be3e7d1f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "be3e7d1f",
        "outputId": "e07aed42-b36b-4248-d30d-39b0b01e9e2f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/gym/core.py:317: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.12/dist-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n"
          ]
        }
      ],
      "source": [
        "# Step 1: Import dependencies and create the environment\n",
        "\n",
        "\n",
        "##--------add the gymnasim to import below this line------##\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# TODO: Initialize the CartPole-v1 environment\n",
        "##-----write your code below this line-----##\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "344d14e3",
      "metadata": {
        "id": "344d14e3"
      },
      "outputs": [],
      "source": [
        "# Step 2: Implement a random policy\n",
        "def random_policy(env):\n",
        "    # TODO: Return a random action from the environmentâ€™s action space\n",
        "    # Hint: env.______\n",
        "    return #----add here\n",
        "    pass\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c5c37ea5",
      "metadata": {
        "id": "c5c37ea5"
      },
      "outputs": [],
      "source": [
        "# Step 3: Run multiple episodes\n",
        "num_episodes = 20\n",
        "rewards = []\n",
        "\n",
        "for episode in range(num_episodes):\n",
        "    # obs =           ##add here code for environment reset\n",
        "    done = False\n",
        "    total_reward = 0\n",
        "\n",
        "    while not done:\n",
        "        action = random_policy(env)\n",
        "        # step_result =       ##----add code for action taken in environment\n",
        "        if len(step_result) == 5:\n",
        "            obs, reward, terminated, truncated, info = step_result\n",
        "            # done =      ##----add the code for determining the termination or truncated condition\n",
        "        else:\n",
        "            obs, reward, done, info = step_result\n",
        "\n",
        "        total_reward += reward\n",
        "        # done =  ##----add the code for determining the termination or truncated condition\n",
        "\n",
        "    rewards.append(total_reward)\n",
        "    print(f\"Episode {episode+1}: Total Reward = {total_reward}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5370ee17",
      "metadata": {
        "id": "5370ee17"
      },
      "outputs": [],
      "source": [
        "# Step 4: Analyze performance\n",
        "plt.plot(rewards)\n",
        "plt.title(\"Random Policy Performance on CartPole-v1\")\n",
        "plt.xlabel(\"Episode\")\n",
        "plt.ylabel(\"Total Reward\")\n",
        "plt.show()\n",
        "\n",
        "print(\"Average reward:\", np.mean(rewards))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fcdfc6e8",
      "metadata": {
        "id": "fcdfc6e8"
      },
      "source": [
        "---\n",
        "### Step 5: Discussion\n",
        "**Questions for Students:**\n",
        "1. Why does the random policy fail to balance the pole?\n",
        "2. What does the reward represent?\n",
        "3. How can you improve the policy?\n",
        "\n",
        "**Outcome:** Youâ€™ve seen why random movement rarely stabilizes CartPole â€” motivating smarter policies!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercise 2: Smarter Random Policy"
      ],
      "metadata": {
        "id": "C_zqby2sPuUy"
      },
      "id": "C_zqby2sPuUy"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Objective\n",
        "\n",
        "Students explore why random fails, then modify the policy to use cart position and pole angle heuristics.\n",
        "Theyâ€™ll complete missing logic to make it â€œless randomâ€ but still rule-based."
      ],
      "metadata": {
        "id": "Ytjuo1TjQFVa"
      },
      "id": "Ytjuo1TjQFVa"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Learning Goals\n",
        "- Use environment state information (position & angle).  \n",
        "- Write a semi-intelligent control rule.  \n",
        "- Visualize agent behavior with `render_mode=\"rgb_array\"`. (for visualization)  "
      ],
      "metadata": {
        "id": "cE0cGqMaQoBs"
      },
      "id": "cE0cGqMaQoBs"
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Setup\n",
        "\n",
        "import gym\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "# Create environment with visual rendering\n",
        "env = gym.make(\"CartPole-v1\", render_mode=\"rgb_array\")\n",
        "\n",
        "# Observation: [cart_pos, cart_vel, pole_angle, pole_ang_vel]\n",
        "print(\"Action space:\", env.action_space)\n",
        "print(\"Observation space:\", env.observation_space)"
      ],
      "metadata": {
        "id": "HzXFzLMiQkih"
      },
      "id": "HzXFzLMiQkih",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def smarter_policy(obs):\n",
        "    cart_pos, cart_vel, pole_angle, pole_ang_vel = obs\n",
        "\n",
        "    # ðŸ§© TODO:\n",
        "    # 1. If pole_angle > 0 (leans right), move right (action = 1)\n",
        "    # 2. Else, move left (action = 0)\n",
        "    # Add slight randomness (10%) to make exploration visible.\n",
        "\n",
        "    pass\n"
      ],
      "metadata": {
        "id": "Cv3wVdsqQ7xO"
      },
      "id": "Cv3wVdsqQ7xO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_episodes = 100\n",
        "for ep in range(num_episodes):\n",
        "    # obs =           ##add here code for environment reset\n",
        "    total_reward = 0\n",
        "    done = False\n",
        "    while not done:\n",
        "        frame = env.render()  # returns the frame array automatically\n",
        "        frames.append(frame)\n",
        "        action = smarter_policy(obs)\n",
        "        # step_result =       ##----add code for action taken in environment\n",
        "        if len(step_result) == 5:\n",
        "            obs, reward, terminated, truncated, info = step_result\n",
        "            # done =      ##----add the code for determining the termination or truncated condition\n",
        "        else:\n",
        "            obs, reward, done, info = step_result\n",
        "        total_reward += reward\n",
        "\n",
        "        time.sleep(0.02)\n",
        "    print(f\"Episode {ep+1} Reward: {total_reward}\")\n",
        "env.close()\n"
      ],
      "metadata": {
        "id": "k04LbbLdFHY1"
      },
      "id": "k04LbbLdFHY1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Code for visualization"
      ],
      "metadata": {
        "id": "tnbDy2pIRPZc"
      },
      "id": "tnbDy2pIRPZc"
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert frames to proper numpy arrays and remove extra dimensions\n",
        "frames_np = [np.array(f).squeeze() for f in frames]  # shape: (H, W, 3)\n",
        "\n",
        "# Create figure\n",
        "fig = plt.figure()\n",
        "patch = plt.imshow(frames_np[0])\n",
        "plt.axis('off')\n",
        "\n",
        "# Animation function\n",
        "def animate(i):\n",
        "    patch.set_data(frames_np[i])\n",
        "    return patch,\n",
        "\n",
        "# Create animation\n",
        "anim = animation.FuncAnimation(fig, animate, frames=len(frames_np), interval=30)\n",
        "plt.close(fig)\n",
        "\n",
        "# Display as HTML5 video\n",
        "HTML(anim.to_jshtml())\n"
      ],
      "metadata": {
        "id": "awUmdr2jKU2g"
      },
      "id": "awUmdr2jKU2g",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FGoGyU3ALAv7"
      },
      "id": "FGoGyU3ALAv7",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}